#!/usr/bin/env bash
set -euo pipefail

pause() { read -rp $'\nüîπ Press Enter to continue...'; }

echo "üîß Step 1 ‚Äî Create + Insert"
make step1
echo "Result:"
docker compose exec spark spark-sql --conf spark.ui.showConsoleProgress=false --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.local.type=hadoop \
  --conf spark.sql.catalog.local.warehouse=s3a://warehouse/iceberg \
  --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 \
  --conf spark.hadoop.fs.s3a.path.style.access=true \
  --conf spark.hadoop.fs.s3a.access.key=minio \
  --conf spark.hadoop.fs.s3a.secret.key=minio123 \
  -e "SET spark.sql.repl.eagerEval.enabled=true; SET spark.sql.debug.maxToStringFields=100; SELECT flight_id, origin, dest, scheduled_dep_ts, actual_dep_ts FROM local.airline.flights ORDER BY scheduled_dep_ts" | column -t | grep -vE 'INFO|WARN|DEBUG'

echo "üß© Step 2 ‚Äî Partition & evolve"
make step2
docker compose exec spark spark-sql --conf spark.ui.showConsoleProgress=false --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.local.type=hadoop \
  --conf spark.sql.catalog.local.warehouse=s3a://warehouse/iceberg \
  --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 \
  --conf spark.hadoop.fs.s3a.path.style.access=true \
  --conf spark.hadoop.fs.s3a.access.key=minio \
  --conf spark.hadoop.fs.s3a.secret.key=minio123 \
  -e "DESCRIBE TABLE EXTENDED local.airline.flights" | grep -vE 'INFO|WARN|DEBUG'
pause

echo "üîÅ Step 3 ‚Äî MERGE upsert (late correction)"
make step3
docker compose exec spark spark-sql --conf spark.ui.showConsoleProgress=false --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.local.type=hadoop \
  --conf spark.sql.catalog.local.warehouse=s3a://warehouse/iceberg \
  --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 \
  --conf spark.hadoop.fs.s3a.path.style.access=true \
  --conf spark.hadoop.fs.s3a.access.key=minio \
  --conf spark.hadoop.fs.s3a.secret.key=minio123 \
  -e "SELECT flight_id, scheduled_dep_ts, actual_dep_ts FROM local.airline.flights WHERE flight_id='LH9001'" | grep -vE 'INFO|WARN|DEBUG'
pause

echo "‚è™ Step 4 ‚Äî Time travel (snapshots)"
make step4
docker compose exec spark spark-sql --conf spark.ui.showConsoleProgress=false --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.local.type=hadoop \
  --conf spark.sql.catalog.local.warehouse=s3a://warehouse/iceberg \
  --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 \
  --conf spark.hadoop.fs.s3a.path.style.access=true \
  --conf spark.hadoop.fs.s3a.access.key=minio \
  --conf spark.hadoop.fs.s3a.secret.key=minio123 \
  -e "SELECT * FROM local.airline.flights.snapshots ORDER BY committed_at" | grep -vE 'INFO|WARN|DEBUG'
pause

echo "üß± Step 5 ‚Äî Schema evolution"
make step5
docker compose exec spark spark-sql --conf spark.ui.showConsoleProgress=false --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.hadoop:hadoop-aws:3.3.4,com.amazonaws:aws-java-sdk-bundle:1.12.262 \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.local=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.local.type=hadoop \
  --conf spark.sql.catalog.local.warehouse=s3a://warehouse/iceberg \
  --conf spark.hadoop.fs.s3a.endpoint=http://minio:9000 \
  --conf spark.hadoop.fs.s3a.path.style.access=true \
  --conf spark.hadoop.fs.s3a.access.key=minio \
  --conf spark.hadoop.fs.s3a.secret.key=minio123 \
  -e "SELECT * FROM local.airline.flights ORDER BY scheduled_dep_ts" | grep -vE 'INFO|WARN|DEBUG'
echo "‚úÖ Demo complete."
