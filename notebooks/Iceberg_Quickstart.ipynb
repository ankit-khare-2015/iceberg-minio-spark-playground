{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "137b31e3",
   "metadata": {},
   "source": [
    "# ðŸ§Š Apache Iceberg + Spark (Jupyter Quickstart)\n",
    "This notebook is pre-configured to connect Spark to your **local Iceberg (Hadoop catalog)** on **MinIO**.\n",
    "\n",
    "**Tip:** Make sure you've run your Docker stack and fetched JARs so they are mounted in the notebook container (see README)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d38933-2f92-450d-bac4-4a2fde15dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset cell (safe to run anytime once the saprk context is created )\n",
    "# Drop the demo table/namespace if they already exist (keeps notebook idempotent)\n",
    "spark.sql(\"DROP TABLE IF EXISTS local.airline.flights PURGE\")\n",
    "# Only drop namespace if empty (avoids errors)\n",
    "spark.sql(\"CREATE NAMESPACE IF NOT EXISTS local.airline\")\n",
    "try:\n",
    "    spark.sql(\"DROP NAMESPACE local.airline\")\n",
    "    spark.sql(\"CREATE NAMESPACE local.airline\")\n",
    "except Exception:\n",
    "    pass\n",
    "print(\"Environment reset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f502629-b886-47f4-8703-7736777b9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "iceberg_jars = \",\".join([\n",
    "    \"/home/jovyan/extra-jars/iceberg-spark-runtime-3.5_2.12-1.6.1.jar\",\n",
    "    \"/home/jovyan/extra-jars/hadoop-aws-3.3.4.jar\",\n",
    "    \"/home/jovyan/extra-jars/aws-java-sdk-bundle-1.12.262.jar\"\n",
    "])\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "    .appName(\"iceberg_fix\")\n",
    "    .config(\"spark.jars\", iceberg_jars)\n",
    "    .config(\"spark.driver.extraClassPath\", iceberg_jars)\n",
    "    .config(\"spark.executor.extraClassPath\", iceberg_jars)\n",
    "    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    .config(\"spark.sql.catalog.local\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    .config(\"spark.sql.catalog.local.type\", \"hadoop\")\n",
    "    .config(\"spark.sql.catalog.local.warehouse\", \"s3a://warehouse/iceberg\")\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\")\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"minio123\")\n",
    "    .getOrCreate())\n",
    "\n",
    "\n",
    "SEP = \"â”€\" * 80\n",
    "\n",
    "def sql(q, title=None, truncate=False):\n",
    "    if title:\n",
    "        print(f\"\\n{SEP}\\n{title}\\n{SEP}\")\n",
    "    return spark.sql(q).show(truncate=truncate)\n",
    "\n",
    "def scalar(q):\n",
    "    \"\"\"Return a single value from a single-row/col query.\"\"\"\n",
    "    df = spark.sql(q).limit(1).toPandas()\n",
    "    return None if df.empty else list(df.iloc[0])[0]\n",
    "\n",
    "def snapshots_df():\n",
    "    return spark.sql(\"SELECT * FROM local.airline.flights.snapshots ORDER BY committed_at\")\n",
    "\n",
    "def print_snapshots(title=\"Snapshots\"):\n",
    "    print(f\"\\n{SEP}\\n{title}\\n{SEP}\")\n",
    "    snapshots_df().show(truncate=False)\n",
    "\n",
    "def section(name):\n",
    "    print(f\"\\n\\nðŸ§Š {name}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee4ed8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"Step 1 â€” Create + Insert\")\n",
    "\n",
    "sql(\"CREATE NAMESPACE IF NOT EXISTS local.airline\")\n",
    "\n",
    "sql(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS local.airline.flights (\n",
    "  flight_id STRING,\n",
    "  carrier   STRING,\n",
    "  origin    STRING,\n",
    "  dest      STRING,\n",
    "  scheduled_dep_ts TIMESTAMP,\n",
    "  actual_dep_ts    TIMESTAMP\n",
    ") USING iceberg\n",
    "\"\"\", \"Create table\")\n",
    "\n",
    "sql(\"\"\"\n",
    "INSERT INTO local.airline.flights VALUES\n",
    "('LH1234','LH','FRA','BOM',timestamp('2025-08-13 10:30:00'),timestamp('2025-08-13 10:29:00')),\n",
    "('LH5678','LH','MUC','LHR',timestamp('2025-08-13 12:00:00'),timestamp('2025-08-13 12:07:00')),\n",
    "('LH9001','LH','FRA','BER',timestamp('2025-08-13 09:10:00'),timestamp('2025-08-13 09:35:00'))\n",
    "\"\"\", \"Insert 3 rows\")\n",
    "\n",
    "sql(\"\"\"\n",
    "SELECT flight_id, origin, dest, scheduled_dep_ts, actual_dep_ts\n",
    "FROM local.airline.flights\n",
    "ORDER BY scheduled_dep_ts\n",
    "\"\"\", \"Current rows\", truncate=False)\n",
    "\n",
    "print_snapshots()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7a5a67-653b-4332-9d99-d62861ecff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"Step 2 â€” Partition & Evolve\")\n",
    "\n",
    "# Add a date column derived from scheduled departure\n",
    "sql(\"ALTER TABLE local.airline.flights ADD COLUMN dep_date DATE\", \"Add dep_date column\")\n",
    "sql(\"UPDATE local.airline.flights SET dep_date = DATE(scheduled_dep_ts)\", \"Backfill dep_date\")\n",
    "\n",
    "# Evolve the partition spec: new writes will be partitioned by dep_date\n",
    "sql(\"ALTER TABLE local.airline.flights ADD PARTITION FIELD dep_date\", \"Add partition field dep_date\")\n",
    "\n",
    "# Insert a couple of new flights (these will be written under the new partition spec)\n",
    "sql(\"\"\"\n",
    "INSERT INTO local.airline.flights (flight_id, carrier, origin, dest, scheduled_dep_ts, actual_dep_ts, dep_date) VALUES\n",
    "('LH1111','LH','TXL','CDG',timestamp('2025-08-14 08:00:00'),timestamp('2025-08-14 07:55:00'), DATE('2025-08-14')),\n",
    "('LH2222','LH','CDG','TXL',timestamp('2025-08-14 19:20:00'),timestamp('2025-08-14 19:44:00'), DATE('2025-08-14'))\n",
    "\"\"\", \"Insert 2 more rows (new partition spec)\")\n",
    "\n",
    "sql(\"\"\"\n",
    "SELECT flight_id, origin, dest, dep_date\n",
    "FROM local.airline.flights\n",
    "ORDER BY dep_date, flight_id\n",
    "\"\"\", \"Rows w/ dep_date\", truncate=False)\n",
    "\n",
    "# Show partition metadata (may be empty until writes exist under new spec)\n",
    "sql(\"SELECT * FROM local.airline.flights.partitions\", \"Partition metadata\")\n",
    "print_snapshots()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2f3b52-5a6a-4afe-aead-173730c685d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"Step 3 â€” MERGE Upsert\")\n",
    "\n",
    "# Capture a \"before-merge\" snapshot id for time travel later\n",
    "before_merge_id = scalar(\"\"\"\n",
    "SELECT snapshot_id FROM local.airline.flights.snapshots\n",
    "ORDER BY committed_at DESC\n",
    "\"\"\")\n",
    "\n",
    "sql(\"\"\"\n",
    "MERGE INTO local.airline.flights t\n",
    "USING (\n",
    "  SELECT 'LH9001' AS flight_id, 'LH' AS carrier, 'FRA' AS origin, 'BER' AS dest,\n",
    "         timestamp('2025-08-13 09:10:00') AS scheduled_dep_ts,\n",
    "         timestamp('2025-08-13 09:20:00') AS actual_dep_ts,\n",
    "         DATE('2025-08-13') AS dep_date\n",
    ") s\n",
    "ON t.flight_id = s.flight_id AND DATE(t.scheduled_dep_ts) = s.dep_date\n",
    "WHEN MATCHED THEN UPDATE SET *\n",
    "WHEN NOT MATCHED THEN INSERT *\n",
    "\"\"\", \"Apply MERGE (correct delay)\")\n",
    "\n",
    "sql(\"\"\"\n",
    "SELECT flight_id, scheduled_dep_ts, actual_dep_ts\n",
    "FROM local.airline.flights\n",
    "WHERE flight_id='LH9001'\n",
    "\"\"\", \"Row after MERGE\", truncate=False)\n",
    "\n",
    "print_snapshots(\"Snapshots (after MERGE)\")\n",
    "print(f\"Saved before_merge_id = {before_merge_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ff2fd-3bde-44f0-a665-57b3936cbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"Step 4 â€” Time Travel\")\n",
    "\n",
    "# If we captured a snapshot ID, read the table as of that snapshot\n",
    "if before_merge_id is not None:\n",
    "    sql(f\"\"\"\n",
    "    SELECT flight_id, scheduled_dep_ts, actual_dep_ts\n",
    "    FROM local.airline.flights VERSION AS OF {int(before_merge_id)}\n",
    "    WHERE flight_id='LH9001'\n",
    "    \"\"\", f\"State BEFORE MERGE (VERSION AS OF {before_merge_id})\", truncate=False)\n",
    "else:\n",
    "    print(\"No before_merge snapshot captured; skipping VERSION AS OF demo.\")\n",
    "\n",
    "# Show current (latest) for comparison\n",
    "sql(\"\"\"\n",
    "SELECT flight_id, scheduled_dep_ts, actual_dep_ts\n",
    "FROM local.airline.flights\n",
    "WHERE flight_id='LH9001'\n",
    "\"\"\", \"Current (latest) state\", truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23aca8-9c93-40d3-a472-141acf45cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "section(\"Step 5 â€” Schema Evolution\")\n",
    "\n",
    "# Add a new column\n",
    "sql(\"ALTER TABLE local.airline.flights ADD COLUMN aircraft_tail STRING\", \"Add new column aircraft_tail\")\n",
    "\n",
    "# Rename a column (dest -> destination)\n",
    "sql(\"ALTER TABLE local.airline.flights RENAME COLUMN dest TO destination\", \"Rename dest -> destination\")\n",
    "\n",
    "# Drop a column (carrier)\n",
    "sql(\"ALTER TABLE local.airline.flights DROP COLUMN carrier\", \"Drop column carrier\")\n",
    "\n",
    "# Insert a new row using the evolved schema (explicit column list)\n",
    "sql(\"\"\"\n",
    "INSERT INTO local.airline.flights\n",
    "(flight_id, origin, destination, scheduled_dep_ts, actual_dep_ts, dep_date, aircraft_tail)\n",
    "VALUES\n",
    "('LH3333','FRA','LHR',timestamp('2025-08-15 07:30:00'),timestamp('2025-08-15 07:37:00'), DATE('2025-08-15'), 'D-AIAB')\n",
    "\"\"\", \"Insert row with evolved schema\")\n",
    "\n",
    "sql(\"\"\"\n",
    "SELECT * FROM local.airline.flights\n",
    "ORDER BY scheduled_dep_ts\n",
    "\"\"\", \"All rows after schema evolution\", truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
